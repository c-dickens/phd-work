{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Hessian Sketching for Regression\n",
    "Code to reproduce results from https://arxiv.org/abs/1411.0347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.datasets import make_regression\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_sketch(nrows, ncols):\n",
    "    '''Generate a Gausian sketching matrix of size\n",
    "    (nrows, ncols)'''\n",
    "    return (1/np.sqrt(nrows))*np.random.randn(nrows, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(nsamples, nfeatures, variance=1):\n",
    "    '''Generates a data matrix of size (nsamples, nfeatures)\n",
    "    which defines a linear relationship on the variables.'''\n",
    "    X, y = make_regression(n_samples=nsamples, n_features=nfeatures,\\\n",
    "                        n_informative=nfeatures,noise=variance)\n",
    "    X[:,0] = np.ones(shape=(nsamples)) # add bias terms\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.10980959],\n",
       "       [ 1.        , -0.69993803],\n",
       "       [ 1.        , -2.18847374],\n",
       "       ..., \n",
       "       [ 1.        ,  1.00829309],\n",
       "       [ 1.        , -2.19282429],\n",
       "       [ 1.        , -0.48726985]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = generate_data(1000,2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_hessian(data, targets, num_iters):\n",
    "    '''\n",
    "    Add docs\n",
    "    '''\n",
    "    A = data\n",
    "    y = targets\n",
    "    n,d = A.shape\n",
    "    x0 = np.zeros(shape=(d,1))\n",
    "    m = n//2 # sketching dimension\n",
    "    \n",
    "    ATy = A.T.dot(y)\n",
    "    covariance_mat = A.T.dot(A)\n",
    "    print(\"ATy shape {}\".format(ATy.shape))\n",
    "    print(\"covar mat prod shape {}\".format(covariance_mat.dot(x0).shape))\n",
    "   \n",
    "    \n",
    "    \n",
    "    for n_iter in range(num_iters):\n",
    "        S = gaussian_sketch(m, n)\n",
    "        S_A = S.dot(A)\n",
    "        print(\"IP shape {}\".format(np.dot(S_A.T, (np.dot(S_A,x0))).shape))\n",
    "        B = S_A.T.dot(S_A)\n",
    "        z = ATy - covariance_mat.dot(x0) + np.dot(S_A.T, (np.dot(S_A,x0)))\n",
    "        sol = sp.linalg.lstsq(B,z)\n",
    "        x_new = sol[0] \n",
    "        \n",
    "        \n",
    "        ### KEEP BELOW AS THIS WILL BE USED FOR LASSO OR\n",
    "        ### PENALISED REGRESSION.\n",
    "        \n",
    "        #x0 = np.zeros((X.shape[0],1))\n",
    "        #xt = np.zeros((2,1))\n",
    "        #x_new = np.zeros((2,1))\n",
    "        #for it in range(20):\n",
    "        #    result = minimize(f2min, x0=x_new,args=(X,y,x_new),\n",
    "        #                     method='L-BFGS-B', jac=False )\n",
    "        #    print(result)\n",
    "        #    x_new = result.x\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(z.shape)\n",
    "        x_new = sp.linalg.solve(B,z)\n",
    "        print(x_new)\n",
    "        print(\"ITERATION {}: ||x_t - x_t+1|| = {}\".\\\n",
    "                  format(n_iter, np.linalg.norm(x0-x_new)))\n",
    "        x0 = x_new\n",
    "        \n",
    "    \n",
    "    return x0\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATy shape (2,)\n",
      "covar mat prod shape (2, 1)\n",
      "IP shape (2, 1)\n",
      "(2, 2)\n",
      "[[  3.15338285  22.03505168]\n",
      " [  2.56171554  17.90062828]]\n",
      "ITERATION 0: ||x_t - x_t+1|| = 28.678950559119645\n",
      "IP shape (2, 2)\n",
      "(2, 2)\n",
      "[[  2.73600785  19.11853944]\n",
      " [  2.63303046  18.39895912]]\n",
      "ITERATION 1: ||x_t - x_t+1|| = 2.9889237134314923\n",
      "IP shape (2, 2)\n",
      "(2, 2)\n",
      "[[  2.71902871  18.9998934 ]\n",
      " [  2.61097173  18.24481823]]\n",
      "ITERATION 2: ||x_t - x_t+1|| = 0.1964972703936377\n",
      "IP shape (2, 2)\n",
      "(2, 2)\n",
      "[[  2.71776352  18.99105259]\n",
      " [  2.6126912   18.25683349]]\n",
      "ITERATION 3: ||x_t - x_t+1|| = 0.015069288255894934\n",
      "IP shape (2, 2)\n",
      "(2, 2)\n",
      "[[  2.71773758  18.99087135]\n",
      " [  2.61294529  18.25860901]]\n",
      "ITERATION 4: ||x_t - x_t+1|| = 0.0018029368504805484\n",
      "IP shape (2, 2)\n",
      "(2, 2)\n",
      "[[  2.71776776  18.99108224]\n",
      " [  2.61294586  18.25861299]]\n",
      "ITERATION 5: ||x_t - x_t+1|| = 0.00021307270573610494\n",
      "IP shape (2, 2)\n",
      "(2, 2)\n",
      "[[  2.71776592  18.99106936]\n",
      " [  2.61294313  18.25859387]]\n",
      "ITERATION 6: ||x_t - x_t+1|| = 2.3290839629701993e-05\n",
      "IP shape (2, 2)\n",
      "(2, 2)\n",
      "[[  2.7177658   18.99106856]\n",
      " [  2.61294301  18.25859305]]\n",
      "ITERATION 7: ||x_t - x_t+1|| = 1.1557091045034067e-06\n",
      "IP shape (2, 2)\n",
      "(2, 2)\n",
      "[[  2.71776581  18.99106863]\n",
      " [  2.61294302  18.2585931 ]]\n",
      "ITERATION 8: ||x_t - x_t+1|| = 8.707995334396457e-08\n",
      "IP shape (2, 2)\n",
      "(2, 2)\n",
      "[[  2.71776581  18.99106862]\n",
      " [  2.61294301  18.25859309]]\n",
      "ITERATION 9: ||x_t - x_t+1|| = 9.789976134867492e-09\n"
     ]
    }
   ],
   "source": [
    "x_hat = iterative_hessian(X,y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.71776581,  18.99106862],\n",
       "       [  2.61294301,  18.25859309]])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.68324845,  18.29311045])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_true = sp.linalg.lstsq(X,y)\n",
    "x_true[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x113f09b70>]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncgoCEZEs93/kyHVUuBwuhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11403dda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(X[:,1], y)\n",
    "ax.plot(X[:,1], X@x_true[0])\n",
    "ax.plot(X[:,1],X@x_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the optimisation step\n",
    "We need to use $x_{t+1} \\leftarrow \\text{argmin}_{x \\in C} \\|SA(x-x_t)\\|_2^2 - (y - Ax_t)^TAx$.  To do this we will invoke the scipy minimizer but we this only minimises with one dimensional inputs so we need a local function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstsq(start_x, sketch, data, target):\n",
    "    S = sketch #\n",
    "    A = data\n",
    "    y = target\n",
    "    x0 = start_x\n",
    "    return norm(S@A@x0-S@y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(lstsq, x0=np.zeros((2,1)),args=(gaussian_sketch(750,1000), X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 4891280.004093261\n",
       " hess_inv: array([[ 0.00092058, -0.0009488 ],\n",
       "       [-0.0009488 ,  0.00102779]])\n",
       "      jac: array([ 0.,  0.])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 68\n",
       "      nit: 9\n",
       "     njev: 17\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([  1.53622863,  19.1349492 ])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f2min(x, data, target, offset):\n",
    "    A = data\n",
    "    S = np.eye(A.shape[0])\n",
    "    #S = gaussian_sketch(nrows=A.shape[0]//2, ncols=A.shape[0] )\n",
    "    #print(S.shape)\n",
    "    #print(A.shape)\n",
    "    y = target\n",
    "    xt = np.ravel(offset)\n",
    "\n",
    "    #print(xt.shape)\n",
    "    #print((S@y).shape)\n",
    "    #print((S@A@(x-xt)).shape)\n",
    "    norm_val = norm(S@A@(x-xt))**2 #(1/2*S.shape[0])*\n",
    "    inner_prod = (y - A@xt).T@A@(x-xt)\n",
    "    \n",
    "    return norm_val - inner_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_f2min(x, data, target, offset):\n",
    "    A = data\n",
    "    y = target\n",
    "    S = np.eye(A.shape[0])\n",
    "    xt = np.ravel(offset)\n",
    "    S_A = S@A\n",
    "    grad = S_A.T@S_A@(x-xt) - A.T@(y-A@xt)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: -88862.213049437763\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-0.00436557, -0.00145519])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 15\n",
      "      nit: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 1.34162354,  9.14655541])\n",
      "      fun: -22215.552874863668\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 0.0003638 , -0.00145519])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 15\n",
      "      nit: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.0124362,  13.7198327])\n",
      "      fun: -5553.8887086430104\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 0.,  0.])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.34784227,  16.00647158])\n",
      "      fun: -1388.4721825066126\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.27373675e-05,  -2.27373675e-05])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 15\n",
      "      nit: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.51554536,  17.14979099])\n",
      "      fun: -347.11806353220624\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ -1.13686838e-05,   5.68434189e-06])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 15\n",
      "      nit: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.5993969 ,  17.72145072])\n",
      "      fun: -86.779516335420283\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  0.00000000e+00,  -1.42108547e-06])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.64132267,  18.00728058])\n",
      "      fun: -21.694880218679973\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 0.,  0.])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.66228556,  18.15019551])\n",
      "      fun: -5.4237204856699348\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ -1.77635684e-07,  -3.55271368e-07])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.672767  ,  18.22165298])\n",
      "      fun: -1.3559303353433532\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  0.00000000e+00,  -6.66133815e-08])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.67800772,  18.25738171])\n",
      "      fun: -0.33898269016691701\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  0.00000000e+00,   1.66533454e-08])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68062808,  18.27524608])\n",
      "      fun: -0.084745725471645647\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ -2.77555756e-09,  -2.77555756e-09])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68193826,  18.28417826])\n",
      "      fun: -0.021186457869908776\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  1.04083409e-09,   3.46944695e-10])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68259335,  18.28864435])\n",
      "      fun: -0.0052966277168437293\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  0.00000000e+00,   1.73472348e-10])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.6829209,  18.2908774])\n",
      "      fun: -0.0013241635541172631\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  0.00000000e+00,  -2.16840434e-11])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68308467,  18.29199392])\n",
      "      fun: -0.00033104420099204507\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  1.62630326e-11,  -1.08420217e-11])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 15\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68316656,  18.29255218])\n",
      "      fun: -8.2762704745932637e-05\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ -7.46062893e-05,   1.06767229e-05])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 12\n",
      "      nit: 2\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68320746,  18.29283132])\n",
      "      fun: -2.0691523340052123e-05\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ -3.73551772e-05,   5.35070543e-06])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 12\n",
      "      nit: 2\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68322793,  18.29297088])\n",
      "      fun: -5.1732997265553683e-06\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ -1.87036358e-05,   2.68154148e-06])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 12\n",
      "      nit: 2\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68323818,  18.29304067])\n",
      "      fun: -1.2935332126656506e-06\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ -9.36485679e-06,   1.34386912e-06])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 12\n",
      "      nit: 2\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68324331,  18.29307556])\n",
      "      fun: -3.2348715651153797e-07\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ -4.68895587e-06,   6.73492938e-07])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 12\n",
      "      nit: 2\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.68324587,  18.293093  ])\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros((X.shape[0],1))\n",
    "xt = np.zeros((2,1))\n",
    "x_new = np.zeros((2,1))\n",
    "for it in range(20):\n",
    "    result = minimize(f2min, x0=x_new,args=(X,y,x_new),\n",
    "         method='L-BFGS-B', jac=False )\n",
    "    print(result)\n",
    "    x_new = result.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -3.2348715651153797e-07\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ -4.68895587e-06,   6.73492938e-07])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 12\n",
       "      nit: 2\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([  2.68324587,  18.293093  ])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now seems to be working in generality.  Keep it here for the time being in case necessary for reference at a later data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
